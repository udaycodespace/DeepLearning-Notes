# ğŸ§  Deep Learning (DLE) â€“ VII Semester Survival Kit  

> *Because why just suffer in class when you can suffer here too?*  

---

### ğŸ“š Course Info (aka: What we signed up for)  
- **Semester:** VII  
- **Branches:** CSE, CST, CSBS, CSE(AIML), CSE(DS) (basically everyone gets dragged in)  
- **Course Code:** CS407  
- **Category:** PEC-IV  
- **Credits:** 3 (but feels like 30)  
- **Scheme:** 2020 (and hopefully future-proof ğŸ¤)  
- **Marks Split:**  
  - Internal: 40 (a.k.a. â€œwrite anything in exam, youâ€™ll still get some marksâ€)  
  - External: 60 (a.k.a. â€œpray to all godsâ€)  
  - Total: 100  

---

### ğŸ¯ Course Outcomes (COs) â€“ Fancy way of saying "what they expect us to magically know"  
- **CO1:** Understand concepts of Deep Learning and ANN.  
- **CO2:** Pretend to summarize Deep Neural Nets.  
- **CO3:** Understand CNN operations (basically filters & magic).  
- **CO4:** Memorize CNN Architectures (LeNet, AlexNet, ResNet â€“ PokÃ©mon evolution line).  
- **CO5:** Fight with RNNs and survive LSTMs.  

---

### ğŸ“ Units Breakdown (with sarcasm included)  

#### **UNIT â€“ I**  
- Deep Learning intro (ML vs DL â€“ the eternal â€œwhy so deep?â€ question).  
- ANN: From neurons to â€œPerceptronsâ€ (a.k.a. dot product with attitude).  
- Fine-tuning hyperparameters (aka endless trial & error).  
- **Case Study:** Heart Disease Prediction (because why not start with saving lives?).  

#### **UNIT â€“ II**  
- Deep Neural Networks â€“ training them without exploding/vanishing gradients (spoiler: good luck).  
- Faster optimizers (SGD isnâ€™t enough, now we bring Adam to the party).  
- Regularization: AKA â€œDonâ€™t let your model cheat by memorizing.â€  

#### **UNIT â€“ III**  
- CNN Part 1: Convolutions, pooling, structured outputs.  
- Applications: Image recognition, object detection, and memes classification (probably).  

#### **UNIT â€“ IV**  
- CNN Part 2: Architectures like LeNet5, AlexNet, GoogLeNet, ResNet.  
- Advantages of CNN (hint: they actually work).  
- **Case Study:** Handwritten digit recognition (MNIST â€“ the â€œHello Worldâ€ of DL).  

#### **UNIT â€“ V**  
- RNNs: From loops to memory cells (aka models that actually â€œrememberâ€).  
- LSTM: Because vanilla RNNs forget faster than students after exams.  
- **Case Study:** Time series prediction (stocks, weather, or just your GPA).  

---

### ğŸ“– Textbooks That Everyone Buys But Reads PDFs Instead  
1. *Hands-On Machine Learning with Scikit-Learn and TensorFlow* â€“ AurÃ©lien GÃ©ron (a.k.a. the only book youâ€™ll actually read).  
2. *Deep Learning* â€“ Ian Goodfellow, Yoshua Bengio, Aaron Courville (a.k.a. The Holy Bible of DL).  

---

### ğŸ“‚ Whatâ€™s in this Repo?  
- âœï¸ My personal notes (written with love, sweat, and caffeine).  
- ğŸ’» Code snippets for each unit (so you donâ€™t cry while coding from scratch).  
- ğŸ“ Case studies implemented in Python/TensorFlow/Keras.  
- âš¡ Bonus: Extra examples, experiments, and probably some meme references.  

---

### ğŸš€ Why this repo?  
Because Deep Learning is *deep*â€¦ and so are the nightmares during exams.  
This repo = Notes + Codes = Survival kit for CS407.  

---

## ğŸŒŸ Contributions  
- If youâ€™re in the same boat (a.k.a same course), feel free to add notes/code.  
- PRs welcome, but donâ€™t send your entire syllabus PDF ğŸ˜….  

---

### ğŸ TL;DR  
This is my **Deep Learning (DLE) â€“ VII Semester** repo with notes + code for each unit, case studies, and extra stuff.  
Use it wisely. Or just stare at the repo and pretend to study.  

